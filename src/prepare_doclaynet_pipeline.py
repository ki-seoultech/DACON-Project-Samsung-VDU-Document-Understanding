%%writefile prep_data.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import argparse
import json
import os
import random
import shutil
import sys
import math
from collections import defaultdict, Counter
from pathlib import Path
from typing import Dict, List, Tuple, Optional

try:
    from PIL import Image
except ImportError:
    Image = None

try:
    import numpy as np
except ImportError:
    np = None

# ------------------------------
# ì „ì—­ ì„¤ì •
# ------------------------------
CLASSES = ["title", "subtitle", "text", "image", "table", "equation"]
CLASS2ID = {c: i for i, c in enumerate(CLASSES)}

# ë°ì´í„°ì…‹ë³„ ì¹´í…Œê³ ë¦¬ ë§¤í•‘í‘œ (source_name -> target_name or None)
# ë²”ìš©ì ìœ¼ë¡œ ìµœëŒ€ì¹˜ í¬ìš© + ì•ˆì „ì œê±°(í—¤ë”/í‘¸í„°/í˜ì´ì§€ë²ˆí˜¸/ì°¸ê³ ë¬¸í—Œ ë“±)
MAPPINGS: Dict[str, Dict[str, Optional[str]]] = {
    # DocLayNet (11 classes; ì¼ë¶€ ëª…ì¹­ì€ ë…¼ë¬¸/ê°€ì´ë“œ ê¸°ì¤€, ëŒ€ì†Œë¬¸ì/í•˜ì´í”ˆ ë³€í˜• í—ˆìš©)
    "doclaynet": {
        "title": "title",
        "section-header": "subtitle",  # ë¶€ì œ/ì„¹ì…˜í—¤ë”ë¥¼ subtitleë¡œ ìºìŠ¤íŒ…
        "section_header": "subtitle",
        "text": "text",
        "caption": "text",
        "list-item": "text",
        "list": "text",
        "figure": "image",
        "picture": "image",
        "table": "table",
        "formula": "equation",  # ë¬¸í—Œì— formula ë¼ë²¨ ì¡´ì¬ ë³´ê³ ë¨
        "equation": "equation",
        # ì œê±° ëŒ€ìƒ
        "footnote": None,
        "page-footer": None,
        "page_header": None,
        "page-header": None,
        "page-footer": None,
        "page number": None,
        "page-number": None,
        "reference": None,
        "bibliography": None,
    },
    # PubLayNet (text, title, list, table, figure)
    "publaynet": {
        "title": "title",
        "text": "text",
        "list": "text",
        "table": "table",
        "figure": "image",
    },
    # DocBank (ë‹¤ì–‘; Equation/Title/Section/Paragraph/Figure/Table/Caption/List ë“±)
    "docbank": {
        "title": "title",
        "section": "subtitle",      # (Sub)sectionë¥˜ë¥¼ subtitleë¡œ ì·¨ê¸‰
        "section*": "subtitle",
        "subsection": "subtitle",
        "subsection*": "subtitle",
        "paragraph": "text",
        "abstract": "text",
        "caption": "text",
        "list": "text",
        "equation": "equation",
        "formula": "equation",
        "figure": "image",
        "table": "table",
        # ì œê±° í›„ë³´
        "footnote": None,
        "header": None,
        "footer": None,
        "page-header": None,
        "page-footer": None,
        "reference": None,
        "bibliography": None,
    },
    # PubTables-1M (VOC: class names: table, table rotated)
    "pubtables1m": {
        "table": "table",
        "table rotated": "table",
    },
}

# ------------------------------
# ìœ í‹¸
# ------------------------------

def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)


def symlink_or_copy(src: Path, dst: Path):
    if dst.exists():
        return
    try:
        os.symlink(src, dst)
    except Exception:
        shutil.copy2(src, dst)


def coco_load(ann_path: Path):
    with open(ann_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    cats = {c["id"]: c.get("name", str(c["id"])).lower() for c in data.get("categories", [])}
    images = {img["id"]: img for img in data.get("images", [])}
    anns_by_img = defaultdict(list)
    for ann in data.get("annotations", []):
        anns_by_img[ann["image_id"]].append(ann)
    return images, anns_by_img, cats


def to_yolo_bbox(x, y, w, h, iw, ih):
    # COCO x,y,w,h -> YOLO x_c, y_c, w, h (normalized)
    x_c = (x + w / 2.0) / iw
    y_c = (y + h / 2.0) / ih
    return x_c, y_c, w / iw, h / ih


def write_yolo_label(lines: List[str], out_path: Path):
    if not lines:
        return
    ensure_dir(out_path.parent)
    with open(out_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines) + "\n")


# ------------------------------
# COCO -> YOLO
# ------------------------------

def cmd_map_coco(args):
    ds = args.dataset.lower()
    mapping = MAPPINGS.get(ds)
    if mapping is None:
        raise ValueError(f"Unknown dataset mapping: {ds}")

    ann_path = Path(args.ann)
    images_dir = Path(args.images_dir)
    out_root = Path(args.out_root)

    out_images = out_root / "images" / args.split
    out_labels = out_root / "labels" / args.split
    ensure_dir(out_images)
    ensure_dir(out_labels)
    ensure_dir(out_root / "meta")

    # classes íŒŒì¼ ê¸°ë¡
    classes_yaml = out_root / "meta" / "classes.yaml"
    if not classes_yaml.exists():
        with open(classes_yaml, "w", encoding="utf-8") as f:
            f.write("names: [title, subtitle, text, image, table, equation]\n")

    images, anns_by_img, cats = coco_load(ann_path)

    kept, skipped = 0, 0
    for img_id, img in images.items():
        file_name = img.get("file_name")
        iw, ih = img.get("width"), img.get("height")
        if not file_name or iw is None or ih is None:
            skipped += 1
            continue
        src_img = images_dir / file_name
        if not src_img.exists():
            # ì¼ë¶€ ë°ì´í„°ì…‹ì€ í•˜ìœ„ í´ë”ê°€ ìˆì„ ìˆ˜ ìˆìŒ â†’ ì „ì²´ íŠ¸ë¦¬ì—ì„œ ê²€ìƒ‰ (ë¹„ìš©â†‘)
            # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ìŠ¤í‚µ
            skipped += 1
            continue

        yolo_lines = []
        for ann in anns_by_img.get(img_id, []):
            cat_name = cats.get(ann["category_id"], str(ann["category_id"]).lower())
            cat_name = cat_name.lower()
            # mapping í‚¤ ë³´ì •(í•˜ì´í”ˆ/ì–¸ë”ìŠ¤ì½”ì–´/ê³µë°± ì œê±°)
            k = cat_name.replace(" ", "-").replace("_", "-")
            tgt = mapping.get(k, mapping.get(cat_name))
            if tgt is None:
                continue
            if tgt not in CLASS2ID:
                continue

            x, y, w, h = ann.get("bbox", [0, 0, 0, 0])
            if w <= 1 or h <= 1:
                continue
            x_c, y_c, ww, hh = to_yolo_bbox(x, y, w, h, iw, ih)
            cid = CLASS2ID[tgt]
            yolo_lines.append(f"{cid} {x_c:.6f} {y_c:.6f} {ww:.6f} {hh:.6f}")

        if not yolo_lines:
            # í•´ë‹¹ ì´ë¯¸ì§€ì—ì„œ ìš°ë¦¬ íƒ€ê¹ƒ í´ë˜ìŠ¤ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
            continue

        # ì¶œë ¥ íŒŒì¼ëª…: datasetprefix_filename
        out_name = f"{ds}__{Path(file_name).stem}{Path(file_name).suffix}"
        dst_img = out_images / out_name
        symlink_or_copy(src_img, dst_img)
        write_yolo_label(yolo_lines, out_labels / f"{Path(out_name).stem}.txt")
        kept += 1

    print(f"[map-coco:{ds}] kept={kept}, skipped={skipped}, out_root={out_root}")


# ------------------------------
# VOC(XML) -> YOLO (PubTables-1M)
# ------------------------------

def parse_voc_xml(xml_path: Path):
    import xml.etree.ElementTree as ET
    tree = ET.parse(xml_path)
    root = tree.getroot()
    size = root.find("size")
    iw = int(size.findtext("width"))
    ih = int(size.findtext("height"))
    objs = []  # (name, xmin, ymin, xmax, ymax)
    for obj in root.findall("object"):
        name = obj.findtext("name").lower()
        bnd = obj.find("bndbox")
        xmin = float(bnd.findtext("xmin"))
        ymin = float(bnd.findtext("ymin"))
        xmax = float(bnd.findtext("xmax"))
        ymax = float(bnd.findtext("ymax"))
        objs.append((name, xmin, ymin, xmax, ymax))
    return iw, ih, objs


def cmd_map_voc(args):
    ds = args.dataset.lower()
    mapping = MAPPINGS.get(ds)
    if mapping is None:
        raise ValueError(f"Unknown dataset mapping: {ds}")

    voc_dir = Path(args.voc_dir)
    images_dir = Path(args.images_dir)
    out_root = Path(args.out_root)

    out_images = out_root / "images" / args.split
    out_labels = out_root / "labels" / args.split
    ensure_dir(out_images)
    ensure_dir(out_labels)
    ensure_dir(out_root / "meta")

    classes_yaml = out_root / "meta" / "classes.yaml"
    if not classes_yaml.exists():
        with open(classes_yaml, "w", encoding="utf-8") as f:
            f.write("names: [title, subtitle, text, image, table, equation]\n")

    xmls = list(voc_dir.rglob("*.xml"))
    kept = 0
    for x in xmls:
        iw, ih, objs = parse_voc_xml(x)
        yolo_lines = []
        for name, xmin, ymin, xmax, ymax in objs:
            tgt = mapping.get(name)
            if tgt != "table":
                continue
            w = xmax - xmin
            h = ymax - ymin
            if w <= 1 or h <= 1:
                continue
            x_c = (xmin + w / 2.0) / iw
            y_c = (ymin + h / 2.0) / ih
            ww = w / iw
            hh = h / ih
            cid = CLASS2ID["table"]
            yolo_lines.append(f"{cid} {x_c:.6f} {y_c:.6f} {ww:.6f} {hh:.6f}")
        if not yolo_lines:
            continue

        img_name = x.with_suffix(".jpg").name
        # ì¼ë¶€ëŠ” .png ê°€ëŠ¥ â†’ ìš°ì„  jpg, ì—†ìœ¼ë©´ png ì‹œë„
        src_img = images_dir / img_name
        if not src_img.exists():
            alt = images_dir / x.with_suffix(".png").name
            if alt.exists():
                src_img = alt
            else:
                continue

        out_name = f"{ds}__{src_img.name}"
        symlink_or_copy(src_img, out_images / out_name)
        write_yolo_label(yolo_lines, out_labels / f"{Path(out_name).stem}.txt")
        kept += 1

    print(f"[map-voc:{ds}] kept={kept}, out_root={out_root}")


# ------------------------------
# í´ë˜ìŠ¤ ê· í˜• ìƒ˜í”Œë§ (ì´ë¯¸ì§€ ë‹¨ìœ„)
# ------------------------------

def cmd_sample_balanced(args):
    yolo_root = Path(args.yolo_root)
    out_root = Path(args.out_split_root)
    ensure_dir(out_root / "images/train")
    ensure_dir(out_root / "labels/train")

    target = int(args.target_per_class)

    # ì´ë¯¸ì§€ë³„ í¬í•¨ í´ë˜ìŠ¤ ì§‘ê³„
    label_files = list((yolo_root / "labels" / "train").glob("*.txt"))
    img_for_lbl = defaultdict(list)  # class_id -> [image_path]
    img_path_by_label = {}

    for lf in label_files:
        img = (yolo_root / "images" / "train" / (lf.stem + ".jpg"))
        if not img.exists():
            img = (yolo_root / "images" / "train" / (lf.stem + ".png"))
        if not img.exists():
            continue
        with open(lf, "r", encoding="utf-8") as f:
            classes = set()
            for line in f:
                try:
                    cid = int(line.strip().split()[0])
                    classes.add(cid)
                except Exception:
                    pass
        for cid in classes:
            img_for_lbl[cid].append(img)
        img_path_by_label[lf] = img

    # ê· í˜• ìƒ˜í”Œë§: ê° í´ë˜ìŠ¤ë³„ targetë§Œí¼ ì´ë¯¸ì§€ ì„ íƒ(ì¤‘ë³µ ê°€ëŠ¥, setìœ¼ë¡œ ê³ ì •)
    selected = set()
    rng = random.Random(args.seed)
    for cid in range(len(CLASSES)):
        pool = img_for_lbl.get(cid, [])
        rng.shuffle(pool)
        for p in pool[:target]:
            selected.add(p)

    # ì„ íƒë³¸ ë³µì‚¬/ë§í¬
    for img in selected:
        lbl = (yolo_root / "labels" / "train" / (img.stem + ".txt"))
        if not lbl.exists():
            continue
        symlink_or_copy(img, out_root / "images/train" / img.name)
        symlink_or_copy(lbl, out_root / "labels/train" / lbl.name)

    # meta/classes.yaml ë™ê¸°í™”
    meta_src = yolo_root / "meta" / "classes.yaml"
    if meta_src.exists():
        ensure_dir(out_root / "meta")
        symlink_or_copy(meta_src, out_root / "meta" / "classes.yaml")

    print(f"[sample-balanced] selected_images={len(selected)} out_root={out_root}")


# ------------------------------
# Split train/val (ì´ë¯¸ì§€ ë‹¨ìœ„ ì¸µí™” ê·¼ì‚¬)
# ------------------------------

def cmd_split(args):
    yolo_root = Path(args.yolo_root)
    val_ratio = float(args.val_ratio)
    seed = int(args.seed)

    images_dir = yolo_root / "images/train"
    labels_dir = yolo_root / "labels/train"

    imgs = sorted([p for p in images_dir.iterdir() if p.suffix.lower() in [".jpg", ".png", ".jpeg"]])
    rng = random.Random(seed)

    # ê°„ë‹¨ ì¸µí™”: ê° ì´ë¯¸ì§€ì˜ ëŒ€í‘œ í´ë˜ìŠ¤(ìµœë¹ˆ) ê¸°ì¤€ ë²„í‚·í™”
    buckets = defaultdict(list)
    for img in imgs:
        lbl = labels_dir / (img.stem + ".txt")
        if not lbl.exists():
            continue
        cnt = Counter()
        with open(lbl, "r", encoding="utf-8") as f:
            for line in f:
                parts = line.strip().split()
                if not parts:
                    continue
                cnt[int(parts[0])] += 1
        rep = cnt.most_common(1)[0][0] if cnt else -1
        buckets[rep].append(img)

    val_set = set()
    for rep, lst in buckets.items():
        k = max(1, int(round(len(lst) * val_ratio)))
        rng.shuffle(lst)
        for p in lst[:k]:
            val_set.add(p)

    # move/symlink
    for phase in ["train", "val"]:
        ensure_dir(yolo_root / f"images/{phase}")
        ensure_dir(yolo_root / f"labels/{phase}")

    # ë¨¼ì € ì „ì²´ë¥¼ trainìœ¼ë¡œ ë³µì‚¬í•´ë‘ê³ , valì€ ë³„ë„ë¡œ ë§í¬
    # (ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ: ì„ íƒëœ valë§Œ ìƒˆ í´ë”ë¡œ ë§í¬, trainì€ ê¸°ì¡´ ìœ ì§€)
    for img in val_set:
        lbl = labels_dir / (img.stem + ".txt")
        symlink_or_copy(img, yolo_root / f"images/val/{img.name}")
        if lbl.exists():
            symlink_or_copy(lbl, yolo_root / f"labels/val/{lbl.name}")

    print(f"[split] total={len(imgs)} val={len(val_set)} val_ratio={val_ratio}")


# ------------------------------
# Reading Order Pair Generation (ì•½ì§€ë„)
# ------------------------------

def guess_reading_order(boxes: List[Tuple[float, float, float, float]], iw: int, ih: int) -> List[int]:
    """ê°„ë‹¨í•œ ì¢Œ->ìš°, ìƒ->í•˜ ì •ë ¬ ê·œì¹™ìœ¼ë¡œ ìˆœì„œë¥¼ ê·¼ì‚¬.
    boxes: (x_center, y_center, w, h) (YOLO norm)
    return: ì¸ë±ìŠ¤ ìˆœì—´
    """
    # ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
    abs_boxes = []
    for i, (xc, yc, w, h) in enumerate(boxes):
        x = (xc - w / 2.0) * iw
        y = (yc - h / 2.0) * ih
        abs_boxes.append((i, x, y))
    # y ìš°ì„ , x ë³´ì¡° ì •ë ¬
    order = sorted(range(len(abs_boxes)), key=lambda k: (abs_boxes[k][2] // 32, abs_boxes[k][1]))
    return order


def tta_boxes(boxes: List[Tuple[float, float, float, float]], aug: str) -> List[Tuple[float, float, float, float]]:
    if aug == "flip":
        return [(1 - xc, yc, w, h) for (xc, yc, w, h) in boxes]
    if aug == "rotate":
        # 90ë„ íšŒì „ (ì‹œê³„) ê¸°ì¤€ ë‹¨ìˆœ ë³€í™˜
        return [(yc, 1 - xc, h, w) for (xc, yc, w, h) in boxes]
    return boxes


def cmd_gen_order_pairs(args):
    yolo_root = Path(args.yolo_root)
    out_csv = Path(args.out_csv)
    tta_list = []
    if args.tta:
        tta_list = [t.strip() for t in args.tta.split(',') if t.strip()]

    images_dir = yolo_root / "images/train"
    labels_dir = yolo_root / "labels/train"
    ensure_dir(out_csv.parent)

    rows = []
    pair_id = 0
    for img in images_dir.iterdir():
        if img.suffix.lower() not in [".jpg", ".png", ".jpeg"]:
            continue
        lbl = labels_dir / (img.stem + ".txt")
        if not lbl.exists():
            continue
        # ì´ë¯¸ì§€ í¬ê¸°
        iw = ih = None
        if Image is not None:
            try:
                with Image.open(img) as im:
                    iw, ih = im.size
            except Exception:
                pass
        if iw is None or ih is None:
            # YOLO normë§Œìœ¼ë¡œë„ ìƒëŒ€ ìˆœì„œ ê·¼ì‚¬ ê°€ëŠ¥í•˜ë¯€ë¡œ ì„ì˜ê°’
            iw, ih = 1000, 1000

        # ë¼ë²¨ ë¡œë“œ
        boxes = []
        with open(lbl, "r", encoding="utf-8") as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) < 5:
                    continue
                cid = int(parts[0])
                if cid not in (CLASS2ID["title"], CLASS2ID["subtitle"], CLASS2ID["text"]):
                    # ì½ê¸°ìˆœì„œ í›„ë³´ëŠ” í…ìŠ¤íŠ¸ì„± ë¸”ë¡ ìœ„ì£¼ë¡œ
                    continue
                xc, yc, w, h = map(float, parts[1:5])
                boxes.append((xc, yc, w, h))

        if len(boxes) < 2:
            continue

        # ê¸°ë³¸ + TTA ë³€í˜•ìœ¼ë¡œ ìˆœì„œ ê·¼ì‚¬
        variants = [("orig", boxes)]
        for t in tta_list:
            variants.append((t, tta_boxes(boxes, t)))

        for tag, bx in variants:
            order = guess_reading_order(bx, iw, ih)
            # ì¸ì ‘ ì–‘ì„± í˜ì–´ ìƒì„±
            for i in range(len(order) - 1):
                src = order[i]
                dst = order[i + 1]
                rows.append([str(img), f"{pair_id}", src, dst, 1])
                pair_id += 1
            # ìŒì„± í˜ì–´(í•˜ë“œë„¤ê±°í‹°ë¸Œ): ë¹„ì—°ì† ì„ì˜ ìŒ
            idxs = list(range(len(bx)))
            random.shuffle(idxs)
            for i in range(0, len(idxs) - 1, 2):
                if abs(i - (i + 1)) <= 1:
                    continue
                rows.append([str(img), f"{pair_id}", idxs[i], idxs[i + 1], 0])
                pair_id += 1

    # ì €ì¥
    with open(out_csv, "w", encoding="utf-8") as f:
        f.write("image_path,pair_id,src_idx,dst_idx,label\n")
        for r in rows:
            f.write(",".join(map(str, r)) + "\n")

    print(f"[gen-order-pairs] pairs={len(rows)} out_csv={out_csv}")


# ------------------------------
# Main
# ------------------------------

def main():
    p = argparse.ArgumentParser(description="VDU Data Prep Pipeline")
    sub = p.add_subparsers(dest="cmd")

    # map-coco
    s = sub.add_parser("map-coco")
    s.add_argument("--dataset", required=True, choices=["doclaynet", "publaynet", "docbank"])  # COCOë¥˜
    s.add_argument("--ann", required=True, help="COCO annotation json path")
    s.add_argument("--images-dir", required=True, help="images root")
    s.add_argument("--out-root", required=True)
    s.add_argument("--split", default="train")
    s.set_defaults(func=cmd_map_coco)

    # map-voc
    s = sub.add_parser("map-voc")
    s.add_argument("--dataset", required=True, choices=["pubtables1m"])  # VOCë¥˜
    s.add_argument("--voc-dir", required=True, help="VOC xml dir")
    s.add_argument("--images-dir", required=True, help="images root")
    s.add_argument("--out-root", required=True)
    s.add_argument("--split", default="train")
    s.set_defaults(func=cmd_map_voc)

    # sample-balanced
    s = sub.add_parser("sample-balanced")
    s.add_argument("--yolo-root", required=True)
    s.add_argument("--target-per-class", required=True, type=int)
    s.add_argument("--out-split-root", required=True)
    s.add_argument("--seed", type=int, default=42)
    s.set_defaults(func=cmd_sample_balanced)

    # split
    s = sub.add_parser("split")
    s.add_argument("--yolo-root", required=True)
    s.add_argument("--val-ratio", type=float, default=0.15)
    s.add_argument("--seed", type=int, default=42)
    s.set_defaults(func=cmd_split)

    # reading order pairs
    s = sub.add_parser("gen-order-pairs")
    s.add_argument("--yolo-root", required=True)
    s.add_argument("--out-csv", required=True)
    s.add_argument("--tta", default="", help="comma-separated: rotate,flip")
    s.set_defaults(func=cmd_gen_order_pairs)

    args = p.parse_args()
    if not hasattr(args, "func"):
        p.print_help()
        sys.exit(1)
    args.func(args)


if __name__ == "__main__":
    main()

import os, glob

# í›„ë³´ ê²½ë¡œ (í•„ìš” ì‹œ ì—¬ê¸°ì— ë” ì¶”ê°€í•´ë„ OK)
coco_candidates = [
    "/content/datasets/doclaynet/COCO/train.json",
    "/content/DocLayNet_core/COCO/train.json",
    "/content/DocLayNet_core.zip/COCO/train.json",
    "/content/COCO/train.json",
]
png_dir_candidates = [
    "/content/datasets/doclaynet/PNG",
    "/content/DocLayNet_core/PNG",
    "/content/DocLayNet_core.zip/PNG",
    "/content/PNG",
]

ANN_PATH = next((p for p in coco_candidates if os.path.isfile(p)), None)
if ANN_PATH is None:
    # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ì „ì²´ íƒìƒ‰(ëŠë¦´ ìˆ˜ ìˆìŒ)
    hits = glob.glob("/content/**/COCO/train.json", recursive=True)
    ANN_PATH = hits[0] if hits else None

PNG_DIR = next((d for d in png_dir_candidates if os.path.isdir(d)), None)
if PNG_DIR is None:
    hits = glob.glob("/content/**/PNG", recursive=True)
    PNG_DIR = hits[0] if hits else None

print("ANN_PATH =", ANN_PATH)
print("PNG_DIR  =", PNG_DIR)

assert ANN_PATH and PNG_DIR, "COCO/train.json ë˜ëŠ” PNG í´ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

# âœ… PNG ë§í¬ êµì • + ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬ì‹¤í–‰ (kept=0 ë¬¸ì œ í•´ê²°)
import os, glob, json, subprocess, sys, random
from pathlib import Path
import pandas as pd

import yaml
from pathlib import Path


def run(cmd):
    cmd = [str(c) for c in cmd]
    print("[cmd]", " ".join(cmd))
    p = subprocess.run(cmd, capture_output=True, text=True)
    if p.stdout: print(p.stdout)
    if p.returncode != 0:
        print("=== STDERR ===")
        print(p.stderr)
        raise subprocess.CalledProcessError(p.returncode, cmd, output=p.stdout, stderr=p.stderr)

# 0) COCO train.json
coco_train = next((p for p in glob.glob("/content/**/COCO/train.json", recursive=True) if os.path.isfile(p)), None)
assert coco_train, "COCO/train.jsonì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
with open(coco_train, "r", encoding="utf-8") as f:
    coco = json.load(f)
names = [im.get("file_name") for im in coco.get("images", []) if im.get("file_name")]
sample = names[:80] if len(names) >= 80 else names

def score_png_dir(png_dir: str) -> int:
    """COCO file_nameì„ ì‹¤ì œë¡œ ì°¾ëŠ” hit ìˆ˜(ì •í™• join + basename fallback)"""
    hit = 0
    for fn in sample:
        p1 = os.path.join(png_dir, fn)
        p2 = os.path.join(png_dir, os.path.basename(fn))
        if os.path.exists(p1) or os.path.exists(p2):
            hit += 1
    return hit

# 1) PNG í›„ë³´ ìˆ˜ì§‘ (realpathë¡œ í‰ê°€)
candidates = []
manual = ["/content/PNG", "/content/DocLayNet_core/PNG", "/content/datasets/doclaynet/PNG"]
for p in manual:
    if os.path.isdir(p): candidates.append(p)
for p in glob.glob("/content/**/PNG", recursive=True):
    if os.path.isdir(p) and p not in candidates:
        candidates.append(p)

scored = []
for d in candidates:
    real = os.path.realpath(d)
    if not os.path.isdir(real):  # ê¹¨ì§„ ë§í¬ ì œì™¸
        continue
    s = score_png_dir(real)
    scored.append((d, real, s))
scored.sort(key=lambda x: x[2], reverse=True)

assert scored and scored[0][2] > 3, f"COCO íŒŒì¼ëª…ê³¼ ì¼ì¹˜í•˜ëŠ” PNG ë””ë ‰í„°ë¦¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í›„ë³´(ìƒìœ„3): {scored[:3]}"
best_path, best_real, best_hit = scored[0]
print("COCO train.json =", coco_train)
print(f"âœ… ì„ íƒëœ PNG ë””ë ‰í„°ë¦¬ = {best_real} (hits={best_hit})")

# 2) ê¹¨ì§„/ìˆœí™˜ ë§í¬ êµì •: /content/datasets/doclaynet/PNG â†’ best_real
link_path = "/content/datasets/doclaynet/PNG"
Path("/content/datasets/doclaynet").mkdir(parents=True, exist_ok=True)
# ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì œê±°(ë””ë ‰í„°ë¦¬/ë§í¬ ëª¨ë‘ ì»¤ë²„)
if os.path.islink(link_path) or os.path.exists(link_path):
    try: os.remove(link_path)
    except IsADirectoryError:
        import shutil; shutil.rmtree(link_path)
os.symlink(best_real, link_path)
print("ğŸ”— /content/datasets/doclaynet/PNG â†’", os.path.realpath(link_path))

# 3) ì¶œë ¥ ë£¨íŠ¸
YOLO_UNI = "/content/workspace/unified_yolo"
YOLO_BAL = "/content/workspace/dataset_balanced"
PAIR_CSV = f"{YOLO_BAL}/meta/order_pairs_train.csv"
os.makedirs(YOLO_UNI, exist_ok=True)
os.makedirs(YOLO_BAL, exist_ok=True)
os.makedirs(os.path.dirname(PAIR_CSV), exist_ok=True)

# (ì„ íƒ) ê¸°ì¡´ ë³€í™˜ë¬¼ ì •ë¦¬: kept=0 ìƒíƒœë¼ë©´ labels/train ë¹„ì–´ìˆìŒ â†’ ì•ˆì „íˆ ë®ì–´ì“°ê¸°
# í•„ìš” ì‹œ ì•„ë˜ ì£¼ì„ ì œê±°í•˜ì—¬ ê¹¨ë—ì´ ì¬ìƒì„±
# import shutil
# shutil.rmtree(YOLO_UNI, ignore_errors=True); os.makedirs(YOLO_UNI, exist_ok=True)
# shutil.rmtree(YOLO_BAL, ignore_errors=True); os.makedirs(YOLO_BAL, exist_ok=True); os.makedirs(os.path.dirname(PAIR_CSV), exist_ok=True)

# 4) COCO â†’ YOLO (train/val)
run([sys.executable, "prep_data.py", "map-coco",
     "--dataset", "doclaynet",
     "--ann", coco_train,
     "--images-dir", os.path.realpath(link_path),
     "--out-root", YOLO_UNI,
     "--split", "train"])

coco_val = next((p for p in glob.glob("/content/**/COCO/val.json", recursive=True) if os.path.isfile(p)), None)
if coco_val:
    run([sys.executable, "prep_data.py", "map-coco",
         "--dataset", "doclaynet",
         "--ann", coco_val,
         "--images-dir", os.path.realpath(link_path),
         "--out-root", YOLO_UNI,
         "--split", "val"])
else:
    print("[warn] val.json ì—†ìŒ â€” split ë‹¨ê³„ì—ì„œ val êµ¬ì„±")

# 5) í´ë˜ìŠ¤ ê· í˜• ìƒ˜í”Œë§ + split
run([sys.executable, "prep_data.py", "sample-balanced",
     "--yolo-root", YOLO_UNI,
     "--target-per-class", "12000",
     "--out-split-root", YOLO_BAL,
     "--seed", "42"])

run([sys.executable, "prep_data.py", "split",
     "--yolo-root", YOLO_BAL,
     "--val-ratio", "0.15",
     "--seed", "42"])

# 6) Reading Order í˜ì–´ ìƒì„±
run([sys.executable, "prep_data.py", "gen-order-pairs",
     "--yolo-root", YOLO_BAL,
     "--out-csv", PAIR_CSV,
     "--tta", "rotate,flip"])

# 7) pos:neg=1:1 ë³´ì • (ì—­ë°©í–¥ + ëœë¤ ë¹„ì—°ì†)
TEXT_CLASS = {0,1,2}
def count_text_boxes(stem, root):
    for split in ["train","val"]:
        lp = Path(root)/"labels"/split/f"{stem}.txt"
        if lp.exists():
            n = 0
            with open(lp,"r",encoding="utf-8") as f:
                for ln in f:
                    if not ln.strip(): continue
                    c = int(float(ln.split()[0]))
                    if c in TEXT_CLASS: n += 1
            return n
    return 0

df = pd.read_csv(PAIR_CSV) if Path(PAIR_CSV).exists() else pd.DataFrame(columns=["image_path","pair_id","src_idx","dst_idx","label"])
if df.empty:
    print("[warn] pairs.csvê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì• ë‹¨ê³„ ë¡œê·¸ì—ì„œ kept>0ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
else:
    g = df.groupby("image_path")
    max_pair_id = 0 if df.empty else int(df["pair_id"].astype(int).max())
    rows_neg, rng = [], random.Random(42)
    for img_path, sub in g:
        sub = sub.copy()
        pos = sub[sub["label"]==1]
        need_neg = len(pos)
        if need_neg == 0:
            continue
        T = count_text_boxes(Path(img_path).stem, YOLO_BAL)
        if T < 2:
            continue
        existing = set((int(r.src_idx), int(r.dst_idx)) for r in sub.itertuples(index=False))
        candidates = []
        # ì—­ë°©í–¥
        for r in pos.itertuples(index=False):
            a,b = int(r.src_idx), int(r.dst_idx)
            if (b,a) not in existing and a!=b:
                candidates.append((b,a))
        # ëœë¤ ë³´ì¶©
        tries = 0
        while len(candidates) < need_neg and tries < need_neg*10:
            tries += 1
            a = rng.randrange(T); b = rng.randrange(T)
            if a==b: continue
            if (a,b) in existing or (a,b) in candidates: continue
            candidates.append((a,b))
        for a,b in candidates[:need_neg]:
            max_pair_id += 1
            rows_neg.append([img_path, str(max_pair_id), a, b, 0])
    if rows_neg:
        df_neg = pd.DataFrame(rows_neg, columns=["image_path","pair_id","src_idx","dst_idx","label"])
        df_out = pd.concat([df, df_neg], ignore_index=True)
        bak = Path(PAIR_CSV).with_suffix(".bak.csv")
        if not bak.exists(): df.to_csv(bak, index=False)
        df_out.to_csv(PAIR_CSV, index=False)
        print(f"[OK] neg {len(df_neg)}ê°œ ì¶”ê°€ â†’ pos:neg = {int((df_out['label']==1).sum())}:{int((df_out['label']==0).sum())}")
        df = df_out
    else:
        print("[warn] neg ì¶”ê°€ í›„ë³´ ì—†ìŒ")

# 8) ìš”ì•½
if not df.empty:
    pos = int((df["label"]==1).sum())
    neg = int((df["label"]==0).sum())
    print(f"[check] pairs rows={len(df)}  pos={pos}  neg={neg}  pos_ratio={pos/max(1,pos+neg):.2%}")


YOLO_BAL = Path("/content/workspace/dataset_balanced")
DATA_YAML = YOLO_BAL/"data.yaml"

data = {
    "path": str(YOLO_BAL),
    "train": "images/train",
    "val": "images/val",
    "names": ["title","subtitle","text","image","table","equation"]
}
with open(DATA_YAML, "w", encoding="utf-8") as f:
    yaml.dump(data, f, allow_unicode=True)

print("[OK] data.yaml ìƒì„± ì™„ë£Œ:", DATA_YAML)
print(DATA_YAML.read_text())

# VDU ë°ì´í„°ì…‹ í†µí•© ê²€ì¦ê¸° (ê´€ëŒ€ ëª¨ë“œ + ì¢…í•© ë¦¬í¬íŠ¸)
# - data.yaml / classes.yaml ì ê²€
# - train/val ì¡´ì¬/ê°œìˆ˜/ë¯¸ìŠ¤ë§¤ì¹˜
# - YOLO ë¼ë²¨ í˜•ì‹ + ë²”ìœ„(Â±TOL) + ê²½ê³„(left/right/top/bot) ì²´í¬
# - í´ë˜ìŠ¤ íˆìŠ¤í† ê·¸ë¨(ìƒ˜í”Œ)
# - pairs.csv ë¬´ê²°ì„±(ì´ë¯¸ì§€/ë¼ë²¨ ì¡´ì¬, í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ ë²”ìœ„) + pos:neg ë¹„ìœ¨
# - ìš”ì•½ ë¦¬í¬íŠ¸ (soft/hard violation, ë¶„í¬, ê²½ê³ )

import os, glob, json, random, statistics as stats
from pathlib import Path
from collections import Counter
import pandas as pd

# ===== ê²½ë¡œ/ì„¤ì • =====
YOLO_BAL = Path("/content/workspace/dataset_balanced")
PAIR_CSV  = YOLO_BAL/"meta"/"order_pairs_train.csv"
DATA_YAML = YOLO_BAL/"data.yaml"
CLASSES_YAML = YOLO_BAL/"meta"/"classes.yaml"

CLASSES = ["title","subtitle","text","image","table","equation"]
CLASS2ID = {c:i for i,c in enumerate(CLASSES)}
TEXT_SET = {CLASS2ID["title"], CLASS2ID["subtitle"], CLASS2ID["text"]}

# í—ˆìš©ì˜¤ì°¨ ë° ë™ì‘
TOL = 2e-3        # 0.002 ì´ë‚´ëŠ” soft ê²½ê³ 
HARD_TOL = 5e-2   # 0.05 ì´ˆê³¼ëŠ” hard ê²½ê³ 
STRICT = False    # Trueë©´ hard violation ì¡´ì¬ ì‹œ AssertionError

# ë¼ë²¨ ìƒ˜í”Œë§ ìˆ˜
SAMPLE_LABELS_PER_SPLIT = 1000
RAND_SEED = 42
random.seed(RAND_SEED)

# ===== ìœ í‹¸ =====
def read_first_n_lines(p, n=3):
    try:
        with open(p, "r", encoding="utf-8") as f:
            out = []
            for _ in range(n):
                out.append(next(f).rstrip("\n"))
            return out
    except Exception:
        return []

def try_load_yaml(path: Path):
    try:
        import yaml
        return yaml.safe_load(path.read_text(encoding="utf-8"))
    except Exception:
        # yaml ë¯¸ì„¤ì¹˜/íŒŒì„œì‹¤íŒ¨ â†’ ë§¤ìš° ë‹¨ìˆœ í‚¤ ì¡´ì¬ë§Œ í™•ì¸
        txt = path.read_text(encoding="utf-8")
        has = all(k in txt for k in ["train","val","names"])
        return {"_raw": txt, "_minimal_ok": has}

def check_files_exist(img_dir: Path, lab_dir: Path):
    imgs = sorted([p for p in img_dir.iterdir() if p.suffix.lower() in [".jpg",".jpeg",".png"]])
    labs = sorted([p for p in lab_dir.iterdir() if p.suffix.lower()==".txt"])
    img_stems = {p.stem for p in imgs}
    lab_stems = {p.stem for p in labs}
    only_img = img_stems - lab_stems
    only_lab = lab_stems - img_stems
    return imgs, labs, only_img, only_lab

def parse_label_line(line):
    parts = line.strip().split()
    if len(parts) < 5:
        raise ValueError(f"label line length < 5: {line}")
    c = int(float(parts[0]))
    xc = float(parts[1]); yc = float(parts[2]); w = float(parts[3]); h = float(parts[4])
    return c, xc, yc, w, h

def within01_soft(v):   # -TOL ~ 1+TOL í—ˆìš©
    return (-TOL <= v <= 1.0 + TOL)
def within01_hard(v):   # -HARD_TOL ~ 1+HARD_TOL í—ˆìš©
    return (-HARD_TOL <= v <= 1.0 + HARD_TOL)

soft_violations = 0
hard_violations = 0
soft_samples = []
hard_samples = []

def validate_label_file(lab_path: Path, img_dir: Path):
    """ë¼ë²¨ 1íŒŒì¼: ì´ë¯¸ì§€ ì¡´ì¬/í˜•ì‹/ë²”ìœ„/ê²½ê³„ ì²´í¬ + í´ë˜ìŠ¤ ì¹´ìš´íŠ¸"""
    global soft_violations, hard_violations
    hist = Counter()

    # ì´ë¯¸ì§€ ì¡´ì¬(ê²½ê³ ë§Œ)
    img_jpg = img_dir/(lab_path.stem + ".jpg")
    img_png = img_dir/(lab_path.stem + ".png")
    img_jpeg = img_dir/(lab_path.stem + ".jpeg")
    if not any(p.exists() for p in [img_jpg, img_png, img_jpeg]):
        print(f"[warn] image missing for {lab_path}")
        return hist

    # ë¼ë²¨ ë¼ì¸
    with open(lab_path, "r", encoding="utf-8") as f:
        lines = [l.strip() for l in f if l.strip()]
    if not lines:
        print(f"[warn] empty label: {lab_path}")
        return hist

    for ln in lines:
        try:
            c, xc, yc, w, h = parse_label_line(ln)
        except Exception as e:
            print(f"[warn] parse error in {lab_path}: {e}")
            continue

        if not (0 <= c < len(CLASSES)):
            print(f"[warn] class out of range ({c}) in {lab_path}")
            continue

        # ê°’ ë²”ìœ„(ê´€ëŒ€)
        values = {"xc":xc, "yc":yc, "w":w, "h":h}
        for k, v in values.items():
            if not within01_soft(v):
                soft_violations += 1
                if len(soft_samples) < 5:
                    soft_samples.append((str(lab_path), k, v))
            if not within01_hard(v):
                hard_violations += 1
                if len(hard_samples) < 3:
                    hard_samples.append((str(lab_path), k, v))

        # ê²½ê³„(left/right/top/bot)
        left  = xc - w/2; right = xc + w/2
        top   = yc - h/2; bot   = yc + h/2
        for k, v in {"left":left, "right":right, "top":top, "bot":bot}.items():
            if not within01_soft(v):
                soft_violations += 1
                if len(soft_samples) < 5:
                    soft_samples.append((str(lab_path), k, v))
            if not within01_hard(v):
                hard_violations += 1
                if len(hard_samples) < 3:
                    hard_samples.append((str(lab_path), k, v))

        hist[c] += 1
    return hist

def class_hist_on_split(root: Path, split: str):
    img_dir = root/"images"/split
    lab_dir = root/"labels"/split
    assert img_dir.exists() and lab_dir.exists(), f"missing split dirs: {split}"
    imgs, labs, only_img, only_lab = check_files_exist(img_dir, lab_dir)
    print(f"[{split}] images={len(imgs)} labels={len(labs)}")
    if only_img:
        print(f"  [warn] labels missing for {len(only_img)} images (e.g., {list(sorted(list(only_img))[:3])})")
    if only_lab:
        print(f"  [warn] images missing for {len(only_lab)} labels (e.g., {list(sorted(list(only_lab))[:3])})")

    # ë¼ë²¨ ìƒ˜í”Œë§
    if len(labs) <= SAMPLE_LABELS_PER_SPLIT:
        sample = labs
    else:
        sample = random.sample(labs, SAMPLE_LABELS_PER_SPLIT)

    hist = Counter()
    for lp in sample:
        hist += validate_label_file(lp, img_dir)
    return hist, len(imgs), len(labs)

def check_yaml_files():
    assert DATA_YAML.exists(), f"data.yaml not found: {DATA_YAML}"
    data = try_load_yaml(DATA_YAML)
    if isinstance(data, dict) and data.get("_minimal_ok"):
        print("[ok] data.yaml keys present (lenient parse)")
    else:
        # ì •ì‹ íŒŒì‹± ì„±ê³µ ì‹œ í•„ìˆ˜ í‚¤/í´ë˜ìŠ¤ëª… í™•ì¸
        assert "path" in data and "train" in data and "val" in data and "names" in data, "data.yaml missing keys"
        assert list(data["names"]) == CLASSES, f"data.yaml names mismatch: {data['names']}"
        print("[ok] data.yaml keys & class names")

    if CLASSES_YAML.exists():
        head = read_first_n_lines(CLASSES_YAML, n=1)
        if head:
            assert "title" in head[0] and "equation" in head[0], f"classes.yaml looks odd: {head[0]}"
        print("[ok] classes.yaml present")
    else:
        print("[warn] classes.yaml not found (optional)")

def text_box_count_for_image(stem: str, root: Path):
    for split in ["train","val"]:
        lp = root/"labels"/split/f"{stem}.txt"
        if lp.exists():
            n = 0
            with open(lp, "r", encoding="utf-8") as f:
                for ln in f:
                    if not ln.strip(): continue
                    c = int(float(ln.split()[0]))
                    if c in TEXT_SET: n += 1
            return n
    return 0

def check_pairs_csv():
    if not PAIR_CSV.exists():
        print("[warn] pairs csv not found:", PAIR_CSV)
        return

    df = pd.read_csv(PAIR_CSV)
    need_cols = {"image_path","pair_id","src_idx","dst_idx","label"}
    missing = need_cols - set(df.columns)
    if missing:
        print(f"[warn] pairs missing columns: {missing}")
        return

    # ê¸°ë³¸ í†µê³„
    total = len(df)
    pos = int((df["label"]==1).sum())
    neg = total - pos
    pos_ratio = pos / max(1, total)
    print(f"[pairs] rows={total}  pos={pos}  neg={neg}  pos_ratio={pos_ratio:.2%}")

    # ì¸ë±ìŠ¤ ë¬´ê²°ì„± & ì¡´ì¬ì„±
    bad_rows = 0
    per_img_counts = []
    per_img_pos_ratio = []

    grp = df.groupby("image_path")
    for ipath, sub in grp:
        ip = Path(ipath)
        # ì´ë¯¸ì§€/ë¼ë²¨ ì¡´ì¬ ì²´í¬(ë§í¬ ê²½ë¡œ ë³´ì •)
        img_ok = False
        for split in ["train","val"]:
            if (YOLO_BAL/"images"/split/ip.name).exists():
                img_ok = True; break
        if not img_ok:
            bad_rows += len(sub)
            continue

        # í…ìŠ¤íŠ¸ ë°•ìŠ¤ ê°œìˆ˜
        T = text_box_count_for_image(ip.stem, YOLO_BAL)
        if T < 2:
            bad_rows += len(sub)
            continue

        # src/dst ë²”ìœ„
        ok = 0
        for r in sub.itertuples(index=False):
            a = int(r.src_idx); b = int(r.dst_idx)
            if 0 <= a < T and 0 <= b < T and a != b:
                ok += 1
        bad_rows += (len(sub) - ok)

        # per-image ë¶„í¬ í†µê³„
        per_img_counts.append(len(sub))
        p = int((sub.label==1).sum())
        per_img_pos_ratio.append(p / max(1,len(sub)))

    ratio_bad = bad_rows / max(1, total)
    print(f"[pairs] invalid_index_rows={bad_rows} ({ratio_bad:.2%})")
    if ratio_bad >= 0.02:
        print("[warn] too many invalid src/dst indices (>2%). í™•ì¸ í•„ìš”")

    # per-image ë¶„í¬ ìš”ì•½
    if per_img_counts:
        print(f"[pairs] per-image pairs: mean={stats.mean(per_img_counts):.1f}, median={stats.median(per_img_counts):.1f}, max={max(per_img_counts)}")
    if per_img_pos_ratio:
        print(f"[pairs] per-image pos_ratio: mean={stats.mean(per_img_pos_ratio):.3f}, median={stats.median(per_img_pos_ratio):.3f}")

# ===== ì‹¤í–‰ =====
print("== YAML / ë©”íƒ€ ì ê²€ ==")
check_yaml_files()

print("\n== train split ì ê²€ ==")
h_tr, n_img_tr, n_lab_tr = class_hist_on_split(YOLO_BAL, "train")

print("\n== val split ì ê²€ ==")
h_va, n_img_va, n_lab_va = class_hist_on_split(YOLO_BAL, "val")

# Split ìš”ì•½
print("\n== split ìš”ì•½ ==")
total_imgs = n_img_tr + n_img_va
val_ratio = (n_img_va / max(1,total_imgs)) if total_imgs else 0.0
print(f"images  train={n_img_tr}  val={n_img_va}  total={total_imgs}  (val_ratio={val_ratio:.2%})")
print(f"labels  train={n_lab_tr}  val={n_lab_va}")

# í´ë˜ìŠ¤ íˆìŠ¤í† ê·¸ë¨(ìƒ˜í”Œ ê¸°ì¤€)
def pretty_hist(h, title):
    total = sum(h.values())
    print(f"\n[{title}] class histogram (sampled)")
    for cid, name in enumerate(CLASSES):
        cnt = h.get(cid,0)
        pct = (cnt/max(1,total))*100
        print(f"  {name:9s} : {cnt:7d} ({pct:5.1f}%)")
    print(f"  total boxes (checked) : {total}")

pretty_hist(h_tr, "train")
pretty_hist(h_va, "val")

# ë¼ë²¨ ë²”ìœ„ ì´íƒˆ ìš”ì•½
print("\n== ë¼ë²¨ ë²”ìœ„ ì´íƒˆ ìš”ì•½ ==")
print(f"soft violations(Â±{TOL} í—ˆìš© ì´ˆê³¼): {soft_violations}")
if soft_samples:
    print("  e.g.", soft_samples[:3])
print(f"hard violations(Â±{HARD_TOL} ì‹¬ê° ì´ˆê³¼): {hard_violations}")
if hard_samples:
    print("  e.g.", hard_samples)

# pairs ì ê²€
print("\n== pairs.csv ì ê²€ ==")
check_pairs_csv()

# STRICT ëª¨ë“œë©´ hard ìœ„ë°˜ ì‹œ ì—ëŸ¬
if STRICT and hard_violations > 0:
    raise AssertionError(f"Hard violations detected: {hard_violations}")

print("\nâœ… ê²€ì¦ ì™„ë£Œ (ê´€ëŒ€ ëª¨ë“œ). ë¦¬í¬íŠ¸ ìˆ˜ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# valíŒŒì¼ ì¤‘ë³µìœ¼ë¡œ ì¸í•œ ë¦¬ë”ë³´ë“œ ì„±ëŠ¥ëˆ„ìˆ˜ ë°©ì§€(ì¤‘ë³µì œê±°)
from pathlib import Path
import shutil

root = Path("/content/workspace/dataset_balanced").resolve()
img_exts = {".png", ".jpg", ".jpeg"}
label_ext = ".txt"

VAL_IMG = root/"images/val"
VAL_LBL = root/"labels/val"
TRN_IMG = root/"images/train"
TRN_LBL = root/"labels/train"

# 1) valì˜ symlinkë¥¼ "ì‹¤íŒŒì¼"ë¡œ ê³ ì • (ë§í¬ íƒ€ê²Ÿì„ ë³µì‚¬í•´ì™€ì„œ ë§í¬ë¥¼ ëŒ€ì²´)
def materialize(dirp):
    fixed = broken = 0
    for p in dirp.iterdir():
        if not p.is_symlink():
            continue
        try:
            # íƒ€ê²Ÿ ì‹¤ì¡´í•˜ë©´ ê·¸ê±¸ ë³µì‚¬í•˜ì—¬ ë§í¬ ëŒ€ì²´
            target = p.resolve(strict=True)
            tmp = p.with_suffix(p.suffix + ".tmpcopy")
            shutil.copy2(target, tmp)
            p.unlink()             # ë§í¬ ì‚­ì œ
            tmp.rename(p)          # ì‹¤ì œ íŒŒì¼ë¡œ êµì²´
            fixed += 1
        except FileNotFoundError:
            # ì´ë¯¸ ê¹¨ì§„ ë§í¬ë©´ ì¹´ìš´íŠ¸ë§Œ (ì´í›„ ì¤‘ë³µ ì œê±°ë¡œ ì¸í•œ ê²ƒì¼ ìˆ˜ ìˆìŒ)
            broken += 1
    return fixed, broken

fix_i, br_i = materialize(VAL_IMG)
fix_l, br_l = materialize(VAL_LBL)
print(f"[VAL ê³ ì •] images: fixed={fix_i}, broken={br_i} | labels: fixed={fix_l}, broken={br_l}")

# 2) val ê¸°ì¤€ìœ¼ë¡œ trainì˜ ì¤‘ë³µë§Œ ì‚­ì œ (valì€ ì ˆëŒ€ ì†ëŒ€ì§€ ì•ŠìŒ)
val_stems = {p.stem for p in VAL_IMG.iterdir() if p.is_file() and p.suffix.lower() in img_exts}

# ì´ë¯¸ì§€ ì¤‘ë³µ ì œê±°
del_img = 0
for p in TRN_IMG.iterdir():
    if p.is_file() and p.suffix.lower() in img_exts and p.stem in val_stems:
        p.unlink()
        del_img += 1

# ë¼ë²¨ ë™ê¸° ì‚­ì œ + ê³ ì•„ ë¼ë²¨ ì •ë¦¬
del_lbl = 0
for p in TRN_LBL.iterdir():
    if p.is_file() and p.suffix.lower() == label_ext and p.stem in val_stems:
        p.unlink()
        del_lbl += 1

# ê³ ì•„ ë¼ë²¨ ì œê±°(ì´ë¯¸ì§€ê°€ ì‚¬ë¼ì ¸ ë‚¨ì€ ë¼ë²¨)
train_img_stems = {p.stem for p in TRN_IMG.iterdir() if p.is_file() and p.suffix.lower() in img_exts}
orphan = [p for p in TRN_LBL.glob("*.txt") if p.stem not in train_img_stems]
for p in orphan:
    p.unlink()

print(f"[train ì •ë¦¬] ì‚­ì œëœ ì¤‘ë³µ ì´ë¯¸ì§€={del_img}, ë¼ë²¨={del_lbl}, ê³ ì•„ ë¼ë²¨ ì¶”ê°€ ì‚­ì œ={len(orphan)}")

# 3) (ê°•ë ¥ ê¶Œì¥) YOLO ìºì‹œ ì œê±°
for p in [
    root/"labels/train.cache", root/"labels/val.cache",
    root/"images/train.cache", root/"images/val.cache",
]:
    try: p.unlink()
    except FileNotFoundError: pass

# 4) ìµœì¢… ì ê²€: valì€ ì‚´ì•„ ìˆê³ (=ê¹¨ì§„ ë§í¬ 0), train/val ê°œìˆ˜ í™•ì¸
def count_files(d, exts):
    return sum(1 for p in d.iterdir() if p.is_file() and (p.suffix.lower() in exts if isinstance(exts, set) else p.suffix.lower()==exts))
def has_broken(dirp):
    return any(p.is_symlink() and not p.exists() for p in dirp.iterdir())

print(f"VAL images={count_files(VAL_IMG, img_exts)}, VAL labels={count_files(VAL_LBL, label_ext)}")
print("VAL ê¹¨ì§„ ë§í¬ ì¡´ì¬?", has_broken(VAL_IMG) or has_broken(VAL_LBL))
print(f"TRAIN images={count_files(TRN_IMG, img_exts)}, TRAIN labels={count_files(TRN_LBL, label_ext)}")
print("âœ… ì¤€ë¹„ ì™„ë£Œ")

